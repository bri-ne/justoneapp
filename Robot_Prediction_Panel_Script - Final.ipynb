{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3c111e0",
   "metadata": {},
   "source": [
    "# This Panel will call comments from  r/all, r/news, and r/politics and predict if robot or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f449a1d",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f23fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import praw\n",
    "from praw.models import MoreComments\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "import joblib\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2789a63e",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a6401b",
   "metadata": {},
   "source": [
    "### Fn: Get the posts, their comments, and clean them up (Hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "175bd0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First Get The Posts\n",
    "def getpostidsHOT(sub):  \n",
    "    \"\"\"\n",
    "    This fn gets the top 10 posts for a subreddit sorted by hot\n",
    "    \"\"\"\n",
    "    subreddit = reddit.subreddit(sub)\n",
    "    title = []\n",
    "    subid = []\n",
    "    for submission in subreddit.hot(limit=10):\n",
    "        tit = submission.title\n",
    "        title.append(tit)\n",
    "        ids = submission.id\n",
    "        subid.append(ids)\n",
    "    df = pd.DataFrame(list(zip(title, subid)), columns=[\"title\", \"id\"])\n",
    "    print(\"got post ids\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec655ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Then Get The Comments\n",
    "def getcomments(id, postnumber):\n",
    "    \"\"\"\n",
    "    This function gets comments and a few other field. It formats in a way ready for the\n",
    "    cleandata fn.\n",
    "    \"\"\"\n",
    "    submission = reddit.submission(id=id)\n",
    "    comid = []\n",
    "    authoru = []\n",
    "    mods = []\n",
    "    created = []\n",
    "    upratio = []\n",
    "    body = []\n",
    "    submission.comments.replace_more(limit=5)  \n",
    "    for comment in submission.comments.list():\n",
    "        ids = comment.id\n",
    "        author = comment.author\n",
    "        mod = comment.distinguished\n",
    "        createds = comment.created_utc\n",
    "        score = comment.score\n",
    "        bodys = comment.body\n",
    "        \n",
    "        comid.append(ids)\n",
    "        authoru.append(author)\n",
    "        mods.append(mod)\n",
    "        created.append(createds)\n",
    "        upratio.append(score)\n",
    "        body.append(bodys)\n",
    "    df = pd.DataFrame(list(zip(comid, authoru, mods, created, upratio, body)), \n",
    "                              columns=[\"comid\", \"authoru\", \"mods\", 'created', 'upratio', 'body'])\n",
    "    postnumber = df\n",
    "    print(\"got comments\")\n",
    "    return postnumber\n",
    "\n",
    "###################################################################\n",
    "## Then get a little bit more data that be useful later\n",
    "def cleandata (df):\n",
    "    \"\"\"\n",
    "    This function extracts usernames from the author feature even where the name is deleted.\n",
    "    It also cleans up the time to make it more useable.\n",
    "    \"\"\"\n",
    "    created_date = []\n",
    "    names = []\n",
    "    for i in range(len(df)):\n",
    "        try:\n",
    "            uname = df.loc[i][1].name\n",
    "            names.append(uname)\n",
    "        except:    \n",
    "            uname = 'deleted'  \n",
    "            names.append(uname)\n",
    "    df[\"username\"] = names\n",
    "    \n",
    "    for row in df[\"created\"]:\n",
    "        date = datetime.datetime.fromtimestamp(row)\n",
    "        created_date.append(date)\n",
    "\n",
    "    print(\"done\")\n",
    "    df[\"created_date\"] = created_date\n",
    "\n",
    "\n",
    "    ## Dealing with TIME~~\n",
    "    df[\"created_date\"] = pd.to_datetime(df[\"created_date\"])\n",
    "    dattime_strings = df[\"created_date\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    df[\"created_date2\"] = dattime_strings\n",
    "    #complaints.head()\n",
    "\n",
    "    df[\"created_date2\"]=df[\"created_date2\"].apply(lambda x:datetime.datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    time_strings = df[\"created_date\"].dt.strftime(\"%H:%M:%S\")\n",
    "    date_strings = df[\"created_date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    df[\"date\"] = date_strings\n",
    "    df[\"time\"] = time_strings\n",
    "    print(\"claned time and got users\")\n",
    "    return df\n",
    "\n",
    "#######################################################################\n",
    "## Then use Eamon Flemming's Cleaning Strategy\n",
    "\n",
    "#Import Regex\n",
    "import re\n",
    "\n",
    "#This function selects any consecutive combination of \\r's and \\n's in a bloc of text, \n",
    "#and replaces that selection with a single space.\n",
    "def replace_linebreaks_w_space(x):\n",
    "    return re.sub('([\\r\\n]+)',' ',x)\n",
    "\n",
    "#This function selects any stretch of two or more consecutive spaces in a bloc of text,\n",
    "#and replaces that selection with a single space.\n",
    "def replace_multispace_w_space(x):\n",
    "    return re.sub('([ ]{2,})',' ',x)\n",
    "\n",
    "\"\"\"\n",
    "I created a fn to tie all  eamon's fn together:\n",
    "\"\"\"\n",
    "def use_eamons(df, sub, body = \"body\"):\n",
    "    #Here we take every comment and apply the two functions to it.\n",
    "    df[body] = df[body].map(replace_linebreaks_w_space)\n",
    "    df[body] = df[body].map(replace_multispace_w_space)\n",
    "    \n",
    "    #Strip away any spaces at the beginning or end of each comment, splits the comment into a list of words, \n",
    "    #and returns the length of that list (i.e.; the number of words in the comment)\n",
    "    df['word_length'] = df[body].map(lambda x: len(x.strip().split(' ')))\n",
    "    df[\"subreddit\"] = sub\n",
    "    \n",
    "    \"\"\"\n",
    "    The last thing we're going to do is remove all comments that are 3 words and shorter, as it's difficult, \n",
    "    and for the most part just unreasonable, to guess anything from comments this short. \n",
    "    We want to focus on accurately predicting comments that have some content.\n",
    "    \"\"\"\n",
    "    comments = df[df['word_length']>=4]\n",
    "    \n",
    "    df_clean = comments\n",
    "    print(\"used eamons\")\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92793080",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Then combine everything but the post ids into one fn\n",
    "def allsteps(df_name, subname):  \n",
    "    i = 0\n",
    "    df_list = []\n",
    "    for row in df_name[\"id\"]:\n",
    "\n",
    "        print(row)\n",
    "        i += 1\n",
    "        name = f\"row{i}\"\n",
    "        df = getcomments(row, name)\n",
    "        df = cleandata(df)\n",
    "        df_list.append(df)\n",
    "\n",
    "    clean_df_list=[]\n",
    "    for df in df_list:\n",
    "        clean_df = use_eamons(df, subname)\n",
    "        clean_df_list.append(clean_df)\n",
    "\n",
    "    final_df = pd.concat(clean_df_list)\n",
    "    \n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9d6821",
   "metadata": {},
   "source": [
    "### Look for Accusations of Bots and Get the Comments Accused "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ed3161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Accusation Comments\n",
    "\n",
    "def findbotaccuse(df, body_column):\n",
    "    \"\"\"\n",
    "    This function looks for the word bot, then cleans for mod bots that say -i am a bot-. it assumes everything \n",
    "    that is keeps is an accusation. While that's likely not true, we'll roll with it and see.\n",
    "    \"\"\"\n",
    "    bot = df[df[body_column].str.contains(r\"\\bbot\\b\")]\n",
    "    Bot = df[df[body_column].str.contains(r\"\\bBot\\b\")]\n",
    "    robot = df[df[body_column].str.contains(r\"\\brobot\\b\")]\n",
    "    Robot = df[df[body_column].str.contains(r\"\\bRobot\\b\")]\n",
    "    \n",
    "    bot_accuse = pd.concat([bot, robot, Robot, Bot])\n",
    "    bot_accuse = bot_accuse.reset_index(drop=True)\n",
    "    \n",
    "    #cleaning for -i am a bot-\n",
    "    only_accuse_bot = bot_accuse[~bot_accuse[body_column].str.contains(r\"\\bI am a bot\\b\")]\n",
    "    print(\"found accusations\")\n",
    "    return only_accuse_bot\n",
    "\n",
    "######################################################\n",
    "## Then get accused\n",
    "\n",
    "def getparentid(df, idcol, bodycol):\n",
    "    \"\"\"\n",
    "    This gets the id of the parents that we can use to get the body\n",
    "    \"\"\"\n",
    "\n",
    "    com_id = []\n",
    "    parent = []\n",
    "    com_body = []\n",
    "    for comid in df[idcol]:\n",
    "        comment_id = comid\n",
    "        com_id.append(comment_id)\n",
    "\n",
    "        # instantiating the Comment class\n",
    "        comment = reddit.comment(comment_id)\n",
    "\n",
    "        # fetching the parent_id attribute\n",
    "        parent_id = comment.parent_id \n",
    "        print(parent_id)\n",
    "        # collecting\n",
    "        parent.append(parent_id)\n",
    "    for body in df[bodycol]:\n",
    "        bodyi = body\n",
    "        com_body.append(bodyi)\n",
    "        \n",
    "    print(\"got parent ID\")\n",
    "    return parent, com_id, com_body\n",
    "\n",
    "\n",
    "def getparentbody(parent, com_id, com_body):\n",
    "    \"\"\"\n",
    "    This gets the body of the parent comment and produces the final df with all the \n",
    "    info we need\n",
    "    \"\"\"\n",
    "    parentbody=[]\n",
    " \n",
    "    for ids in parent:\n",
    "        try:\n",
    "            parent_id = ids\n",
    "            # but also running through next step\n",
    "            comment_parent = reddit.comment(parent_id)\n",
    "            parent_body = comment_parent.body\n",
    "\n",
    "\n",
    "            print(\"got parent body\")\n",
    "        except:\n",
    "            parent_body = \" \"\n",
    "            print(\"no body\")\n",
    "        \n",
    "        parentbody.append(parent_body)    \n",
    "    \n",
    "    lil_df = pd.DataFrame(list(zip(com_id, com_body, parent, parentbody)), columns=[\"child_id\", \"child_body\", \"parent_id\", \"parent_body\"])\n",
    "    \n",
    "    return lil_df\n",
    "\n",
    "## putting get accused into one neat fn: \n",
    "\n",
    "def getparentall(df, idcol, bodycol):\n",
    "    \"\"\"\n",
    "    This combines the get parent body and get id. it wasn't working when i had them in one singular fn, but it works\n",
    "    like this\n",
    "    \"\"\"\n",
    "    parent_list, com_id, com_body  = getparentid(df, idcol, bodycol)\n",
    "    final_df = getparentbody(parent_list, com_id, com_body)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49858842",
   "metadata": {},
   "source": [
    "### Last Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ecf6a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the loaded pickled model to make predictions\n",
    "def getpredictions(model, Xval, df):\n",
    "    \"\"\"\n",
    "    This function predicts with the defined model on the validation set\n",
    "    \"\"\"\n",
    "    predictions = pd.DataFrame(model.predict_proba(Xval))\n",
    "    predictions['parent_body'] = df['parent_body']\n",
    "    predictions['child_body'] = df['child_body']\n",
    "    predictions['child_id'] = df['child_id']\n",
    "    predictions['parent_id'] = df['parent_id']\n",
    "    predictions['pred'] = model.predict(Xval)\n",
    "    predictions.columns = ['bot', 'human','parent_body','child_body','child_id','parent_id','pred']\n",
    "    predictions = predictions[['child_id','child_body','parent_id','parent_body','pred', 'human','bot']]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34287712",
   "metadata": {},
   "source": [
    "## setup credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fd2e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID =  \"4OwAYLyOEKKPQjb-Hgpt6g\"\n",
    "SECRET_TOKEN =  \"-05d1ux9vDdkVt67yPMojiKywTjRsQ\"\n",
    "user_agent =  \"MUSA550KarmaMine1\"\n",
    "password = 'KarmaMine1$$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3bb0658",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id=CLIENT_ID, \\\n",
    "                     client_secret=SECRET_TOKEN, \\\n",
    "                     user_agent=user_agent, \\\n",
    "                     username=user_agent, \\\n",
    "                     password=password)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6420bf22",
   "metadata": {},
   "source": [
    "## Call Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4733e1",
   "metadata": {},
   "source": [
    "### r/all (sorted by HOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66498e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got post ids\n",
      "rl0rbu\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rl14fx\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rkzlrz\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rkz9so\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rkylhs\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rky28q\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rky25x\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rkx8ka\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rkyn0t\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rkx61s\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n"
     ]
    }
   ],
   "source": [
    "rall_df = getpostidsHOT(\"all\")\n",
    "rall_comments = allsteps(rall_df, \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4fee22",
   "metadata": {},
   "source": [
    "### r/news  (sorted by HOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af21c0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got post ids\n",
      "rkulbg\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rkqjyx\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rko3lm\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rkzeoj\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rkp52l\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rkz5f0\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rl1y03\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rktnd9\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rkyknx\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rkpbb9\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n"
     ]
    }
   ],
   "source": [
    "rnews_df = getpostidsHOT(\"news\")\n",
    "rnews_comments = allsteps(rnews_df, \"news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a3b590",
   "metadata": {},
   "source": [
    "### r/politics  (sorted by HOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "063e6a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got post ids\n",
      "rkt3lz\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rkwvl2\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rkzdyh\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rkwyar\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rkn2t0\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rknwk8\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rklwct\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rknp3p\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rkrlfz\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "rkov6q\n",
      "got comments\n",
      "done\n",
      "claned time and got users\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n",
      "used eamons\n"
     ]
    }
   ],
   "source": [
    "rpolitics_df = getpostidsHOT(\"politics\")\n",
    "rpolitics_comments = allsteps(rpolitics_df, \"politics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c57811",
   "metadata": {},
   "source": [
    "## Get Accusations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d84e66fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found accusations\n",
      "found accusations\n",
      "found accusations\n"
     ]
    }
   ],
   "source": [
    "## rall\n",
    "rall_accuse = findbotaccuse(rall_comments, \"body\")\n",
    "\n",
    "\n",
    "## rnews\n",
    "rnews_accuse = findbotaccuse(rnews_comments, \"body\")\n",
    "\n",
    "\n",
    "## rpolitics\n",
    "rpolitics_accuse = findbotaccuse(rpolitics_comments, \"body\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdef7e15",
   "metadata": {},
   "source": [
    "## Getting the Accused (Parent of the Accusation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ee2930f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1_hpdb1m4\n",
      "t1_hpd3d6s\n",
      "t1_hpdbr6q\n",
      "t1_hpdg389\n",
      "t1_hpdiiw5\n",
      "got parent ID\n",
      "got parent body\n",
      "got parent body\n",
      "got parent body\n",
      "got parent body\n",
      "got parent body\n",
      "t1_hpbyjuu\n",
      "got parent ID\n",
      "got parent body\n",
      "t1_hpbikxs\n",
      "t3_rklwct\n",
      "t1_hpadwgg\n",
      "t1_hpar46b\n",
      "got parent ID\n",
      "got parent body\n",
      "no body\n",
      "got parent body\n",
      "got parent body\n"
     ]
    }
   ],
   "source": [
    "## rall\n",
    "rall_parent = getparentall(rall_accuse, \"comid\", \"body\")\n",
    "\n",
    "\n",
    "## rnews\n",
    "rnews_parent = getparentall(rnews_accuse, \"comid\", \"body\")\n",
    "\n",
    "\n",
    "## rpolitics\n",
    "rpolitics_parent = getparentall(rpolitics_accuse, \"comid\", \"body\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a0f76a",
   "metadata": {},
   "source": [
    "## Cleaning the Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "472b0a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used eamons\n"
     ]
    }
   ],
   "source": [
    "rall_parent_clean = use_eamons(rall_parent, \"rall\", \"parent_body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bb4a94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used eamons\n"
     ]
    }
   ],
   "source": [
    "rnews_parent_clean = use_eamons(rnews_parent, \"rnews\", \"parent_body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fdddac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used eamons\n"
     ]
    }
   ],
   "source": [
    "rpolitics_parent_clean = use_eamons(rpolitics_parent, \"rpolitics\", \"parent_body\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9830e62e",
   "metadata": {},
   "source": [
    "## Bringing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ea6b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import SGDClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3a3db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r'./data/rallsubsimLogit.joblib.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56247e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b586b83c",
   "metadata": {},
   "source": [
    "## Testing on the Accusations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d81aa9",
   "metadata": {},
   "source": [
    "### r/all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5c5eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xall = rall_parent_clean['parent_body']\n",
    "rall_predictions = getpredictions(model, Xall, rall_parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c74dd3",
   "metadata": {},
   "source": [
    "### r/news  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e09efee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnews = rnews_parent_clean['parent_body']\n",
    "news_predictions = getpredictions(model, Xnews, rnews_parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303d27eb",
   "metadata": {},
   "source": [
    "### r/politics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdba28f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpolitics = rpolitics_parent_clean['parent_body']\n",
    "politics_predictions = getpredictions(model, Xpolitics, rpolitics_parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b1eed",
   "metadata": {},
   "source": [
    "# combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "065b24a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [rall_predictions, news_predictions, politics_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1c691a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "accused = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0fd62e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>child_id</th>\n",
       "      <th>child_body</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>parent_body</th>\n",
       "      <th>pred</th>\n",
       "      <th>human</th>\n",
       "      <th>bot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpdgz49</td>\n",
       "      <td>I downvoted you and I’m not a bot. Your belief...</td>\n",
       "      <td>t1_hpdb1m4</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>all</td>\n",
       "      <td>0.749700</td>\n",
       "      <td>0.250300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hpd63gn</td>\n",
       "      <td>Whoa... someone is project hard here. Or are y...</td>\n",
       "      <td>t1_hpd3d6s</td>\n",
       "      <td>China and TCM related reddit: \"fuck this pos\"</td>\n",
       "      <td>all</td>\n",
       "      <td>0.554170</td>\n",
       "      <td>0.445830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hpdg389</td>\n",
       "      <td>Don't worry, it seems like they're an advanced...</td>\n",
       "      <td>t1_hpdbr6q</td>\n",
       "      <td>I had to check the date on my watch. Damn you!</td>\n",
       "      <td>all</td>\n",
       "      <td>0.554178</td>\n",
       "      <td>0.445822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpdkbqt</td>\n",
       "      <td>What if I am an android? Then I’d technically ...</td>\n",
       "      <td>t1_hpdg389</td>\n",
       "      <td>Don't worry, it seems like they're an advanced...</td>\n",
       "      <td>SubSimulatorGPT2</td>\n",
       "      <td>0.362779</td>\n",
       "      <td>0.637221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpc4ybs</td>\n",
       "      <td>We need robot coyotes to howl at the right time.</td>\n",
       "      <td>t1_hpbyjuu</td>\n",
       "      <td>That's amazing. \"Hang on, let me double my fer...</td>\n",
       "      <td>all</td>\n",
       "      <td>0.923328</td>\n",
       "      <td>0.076672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  child_id                                         child_body   parent_id  \\\n",
       "0  hpdgz49  I downvoted you and I’m not a bot. Your belief...  t1_hpdb1m4   \n",
       "1  hpd63gn  Whoa... someone is project hard here. Or are y...  t1_hpd3d6s   \n",
       "2  hpdg389  Don't worry, it seems like they're an advanced...  t1_hpdbr6q   \n",
       "3  hpdkbqt  What if I am an android? Then I’d technically ...  t1_hpdg389   \n",
       "0  hpc4ybs   We need robot coyotes to howl at the right time.  t1_hpbyjuu   \n",
       "\n",
       "                                         parent_body              pred  \\\n",
       "0                                          [deleted]               all   \n",
       "1      China and TCM related reddit: \"fuck this pos\"               all   \n",
       "2     I had to check the date on my watch. Damn you!               all   \n",
       "3  Don't worry, it seems like they're an advanced...  SubSimulatorGPT2   \n",
       "0  That's amazing. \"Hang on, let me double my fer...               all   \n",
       "\n",
       "      human       bot  \n",
       "0  0.749700  0.250300  \n",
       "1  0.554170  0.445830  \n",
       "2  0.554178  0.445822  \n",
       "3  0.362779  0.637221  \n",
       "0  0.923328  0.076672  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accused.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512ee3ef",
   "metadata": {},
   "source": [
    "## Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "024a9569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a7fff776",
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs = [textblob.TextBlob(posts) for posts in accused[\"parent_body\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "25d61172",
   "metadata": {},
   "outputs": [],
   "source": [
    "accused['Polarity'] = [blob.sentiment.polarity for blob in blobs]\n",
    "accused['Subjectivity'] = [blob.sentiment.subjectivity for blob in blobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7b5fdc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "accused.rename(columns={'parent_body': 'accused', 'child_body': 'accuser'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "334deca6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>child_id</th>\n",
       "      <th>accuser</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>accused</th>\n",
       "      <th>pred</th>\n",
       "      <th>human</th>\n",
       "      <th>bot</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpdgz49</td>\n",
       "      <td>I downvoted you and I’m not a bot. Your belief...</td>\n",
       "      <td>t1_hpdb1m4</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>all</td>\n",
       "      <td>0.749700</td>\n",
       "      <td>0.250300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hpd63gn</td>\n",
       "      <td>Whoa... someone is project hard here. Or are y...</td>\n",
       "      <td>t1_hpd3d6s</td>\n",
       "      <td>China and TCM related reddit: \"fuck this pos\"</td>\n",
       "      <td>all</td>\n",
       "      <td>0.554170</td>\n",
       "      <td>0.445830</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hpdg389</td>\n",
       "      <td>Don't worry, it seems like they're an advanced...</td>\n",
       "      <td>t1_hpdbr6q</td>\n",
       "      <td>I had to check the date on my watch. Damn you!</td>\n",
       "      <td>all</td>\n",
       "      <td>0.554178</td>\n",
       "      <td>0.445822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpdkbqt</td>\n",
       "      <td>What if I am an android? Then I’d technically ...</td>\n",
       "      <td>t1_hpdg389</td>\n",
       "      <td>Don't worry, it seems like they're an advanced...</td>\n",
       "      <td>SubSimulatorGPT2</td>\n",
       "      <td>0.362779</td>\n",
       "      <td>0.637221</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpc4ybs</td>\n",
       "      <td>We need robot coyotes to howl at the right time.</td>\n",
       "      <td>t1_hpbyjuu</td>\n",
       "      <td>That's amazing. \"Hang on, let me double my fer...</td>\n",
       "      <td>all</td>\n",
       "      <td>0.923328</td>\n",
       "      <td>0.076672</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  child_id                                            accuser   parent_id  \\\n",
       "0  hpdgz49  I downvoted you and I’m not a bot. Your belief...  t1_hpdb1m4   \n",
       "1  hpd63gn  Whoa... someone is project hard here. Or are y...  t1_hpd3d6s   \n",
       "2  hpdg389  Don't worry, it seems like they're an advanced...  t1_hpdbr6q   \n",
       "3  hpdkbqt  What if I am an android? Then I’d technically ...  t1_hpdg389   \n",
       "0  hpc4ybs   We need robot coyotes to howl at the right time.  t1_hpbyjuu   \n",
       "\n",
       "                                             accused              pred  \\\n",
       "0                                          [deleted]               all   \n",
       "1      China and TCM related reddit: \"fuck this pos\"               all   \n",
       "2     I had to check the date on my watch. Damn you!               all   \n",
       "3  Don't worry, it seems like they're an advanced...  SubSimulatorGPT2   \n",
       "0  That's amazing. \"Hang on, let me double my fer...               all   \n",
       "\n",
       "      human       bot  Polarity  Subjectivity  \n",
       "0  0.749700  0.250300  0.000000          0.00  \n",
       "1  0.554170  0.445830 -0.200000          0.50  \n",
       "2  0.554178  0.445822  0.000000          0.00  \n",
       "3  0.362779  0.637221  0.144444          0.35  \n",
       "0  0.923328  0.076672  0.366667          0.55  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accused.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c8ca25",
   "metadata": {},
   "source": [
    "## HV Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "bfa9ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "540a21f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e4d98c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['human', 'bot', 'Polarity', 'Subjectivity']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accused_plot(x='human', y='bot', width= 320, color='#4b2362', hover_cols=[\"accuser\", \"accused\"]):\n",
    "    return accused.hvplot.scatter(x, y, c=c, padding=0.1)\n",
    "\n",
    "columns = list(accused.columns[-4:])\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4de0266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the widgets\n",
    "x = pn.widgets.Select(value=\"human\", options=columns, name=\"x\")\n",
    "y = pn.widgets.Select(value=\"bot\", options=columns, name=\"y\")\n",
    "#color = pn.widgets.ColorPicker(name=\"Color\", value=\"#4b2362\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "58ec5a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dashboard\n",
    "reactive_dashboard = pn.Row(\n",
    "    pn.Column(\n",
    "        pn.Row(\"Bot Accused Comments\"),\n",
    "        pn.Row(\n",
    "            pn.Column(x, y)), # Title and widgets\n",
    "    pn.bind(accused.hvplot.scatter, x, y, width= 320,  c='#4b2362', hover_cols=[\"accuser\", \"accused\"])), # Main chart\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "578e3f67",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='11264'>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"764e3c90-acf5-4616-8ba1-04ec1671f5aa\" data-root-id=\"11264\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  function embed_document(root) {\n",
       "    var docs_json = {\"3621857a-be9f-4a85-a5af-c078f3f12b04\":{\"defs\":[{\"extends\":null,\"module\":null,\"name\":\"ReactiveHTML1\",\"overrides\":[],\"properties\":[]},{\"extends\":null,\"module\":null,\"name\":\"FlexBox1\",\"overrides\":[],\"properties\":[{\"default\":\"flex-start\",\"kind\":null,\"name\":\"align_content\"},{\"default\":\"flex-start\",\"kind\":null,\"name\":\"align_items\"},{\"default\":\"row\",\"kind\":null,\"name\":\"flex_direction\"},{\"default\":\"wrap\",\"kind\":null,\"name\":\"flex_wrap\"},{\"default\":\"flex-start\",\"kind\":null,\"name\":\"justify_content\"}]},{\"extends\":null,\"module\":null,\"name\":\"TemplateActions1\",\"overrides\":[],\"properties\":[{\"default\":0,\"kind\":null,\"name\":\"open_modal\"},{\"default\":0,\"kind\":null,\"name\":\"close_modal\"}]},{\"extends\":null,\"module\":null,\"name\":\"MaterialTemplateActions1\",\"overrides\":[],\"properties\":[{\"default\":0,\"kind\":null,\"name\":\"open_modal\"},{\"default\":0,\"kind\":null,\"name\":\"close_modal\"}]}],\"roots\":{\"references\":[{\"attributes\":{},\"id\":\"11286\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"11290\",\"type\":\"BasicTicker\"},{\"attributes\":{\"axis_label\":\"human\",\"formatter\":{\"id\":\"11316\"},\"major_label_policy\":{\"id\":\"11317\"},\"ticker\":{\"id\":\"11286\"}},\"id\":\"11285\",\"type\":\"LinearAxis\"},{\"attributes\":{\"css_classes\":[\"markdown\"],\"margin\":[5,5,5,5],\"name\":\"Markdown16094\",\"text\":\"&lt;p&gt;Bot Accused Comments&lt;/p&gt;\"},\"id\":\"11267\",\"type\":\"panel.models.markup.HTML\"},{\"attributes\":{\"children\":[{\"id\":\"11270\"},{\"id\":\"11271\"}],\"margin\":[0,0,0,0],\"name\":\"Column16097\"},\"id\":\"11269\",\"type\":\"Column\"},{\"attributes\":{\"children\":[{\"id\":\"11267\"}],\"margin\":[0,0,0,0],\"name\":\"Row16096\"},\"id\":\"11266\",\"type\":\"Row\"},{\"attributes\":{\"source\":{\"id\":\"11306\"}},\"id\":\"11313\",\"type\":\"CDSView\"},{\"attributes\":{\"data_source\":{\"id\":\"11306\"},\"glyph\":{\"id\":\"11309\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"11311\"},\"nonselection_glyph\":{\"id\":\"11310\"},\"selection_glyph\":{\"id\":\"11314\"},\"view\":{\"id\":\"11313\"}},\"id\":\"11312\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"children\":[{\"id\":\"11276\"}],\"margin\":[0,0,0,0],\"name\":\"Row16103\"},\"id\":\"11272\",\"type\":\"Row\"},{\"attributes\":{},\"id\":\"11293\",\"type\":\"SaveTool\"},{\"attributes\":{\"end\":0.858563421717838,\"reset_end\":0.858563421717838,\"reset_start\":0.0055905434397648945,\"start\":0.0055905434397648945,\"tags\":[[[\"bot\",\"bot\",null]]]},\"id\":\"11274\",\"type\":\"Range1d\"},{\"attributes\":{\"overlay\":{\"id\":\"11298\"}},\"id\":\"11296\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"11281\",\"type\":\"LinearScale\"},{\"attributes\":{\"callback\":null,\"renderers\":[{\"id\":\"11312\"}],\"tags\":[\"hv_created\"],\"tooltips\":[[\"human\",\"@{human}\"],[\"bot\",\"@{bot}\"],[\"accuser\",\"@{accuser}\"],[\"accused\",\"@{accused}\"]]},\"id\":\"11275\",\"type\":\"HoverTool\"},{\"attributes\":{\"text_color\":\"black\",\"text_font_size\":\"12pt\"},\"id\":\"11277\",\"type\":\"Title\"},{\"attributes\":{\"angle\":{\"value\":0.0},\"fill_alpha\":{\"value\":1.0},\"fill_color\":{\"value\":\"#4b2362\"},\"hatch_alpha\":{\"value\":1.0},\"hatch_color\":{\"value\":\"black\"},\"hatch_scale\":{\"value\":12.0},\"hatch_weight\":{\"value\":1.0},\"line_alpha\":{\"value\":1.0},\"line_cap\":{\"value\":\"butt\"},\"line_color\":{\"value\":\"#4b2362\"},\"line_dash\":{\"value\":[]},\"line_dash_offset\":{\"value\":0},\"line_join\":{\"value\":\"bevel\"},\"line_width\":{\"value\":1},\"marker\":{\"value\":\"circle\"},\"size\":{\"value\":5.477225575051661},\"x\":{\"field\":\"human\"},\"y\":{\"field\":\"bot\"}},\"id\":\"11314\",\"type\":\"Scatter\"},{\"attributes\":{\"data\":{\"accused\":[\"[deleted]\",\"China and TCM related reddit: \\\"fuck this pos\\\"\",\"I had to check the date on my watch. Damn you!\",\"Don't worry, it seems like they're an advanced AI bot that just spams comments, some of which turn out rather odd, like this one. At this point, I assume about 90% of comments are from bots in order to drive engagement. If you really pay attention to the wording of some comments, you'll start to notice it.\",\"That's amazing. \\\"Hang on, let me double my fertility real quick.\\\"\",\"This should be a bots job\",\" \",\"Sloped forehead and angular jaw suitable for chewing tough root fibers and shelling beetles for protein. Heavily muscled forearms. Closely set eyes to spot predators at distance. Rudimentary language skills and intelligence capable of solving simple puzzles and fashioning basic tools. I\\u2019d say early cromagnon, a fine example of proto-human.\"],\"accuser\":[\"I downvoted you and I\\u2019m not a bot. Your beliefs would give the government far too much power, and absolutely no one wants the government to have more power over individuals.\",\"Whoa... someone is project hard here. Or are you just a bot?\",\"Don't worry, it seems like they're an advanced AI bot that just spams comments, some of which turn out rather odd, like this one. At this point, I assume about 90% of comments are from bots in order to drive engagement. If you really pay attention to the wording of some comments, you'll start to notice it.\",\"What if I am an android? Then I\\u2019d technically be a bot but I would think I was a human and I\\u2019d still be using my fat thumbs to type this comment.\",\"We need robot coyotes to howl at the right time.\",\"I don't program and so I will continue with my minor corrections until someone can create a bot that does this for me.\",\"This is the best tl;dr I could make, [original](https://www.newsweek.com/marjorie-taylor-greene-refers-yellow-people-speech-gop-diversity-1660982) reduced by 86%. (I'm a bot) ***** > Congresswoman Marjorie Taylor Greene referred to &quot;Yellow people&quot; while pushing back against claims of the GOP being a &quot;White supremacist party.\\\" > &quot;So I&#039;m walking around and seeing some good people and I see white people, Black people, brown people, yellow people...&quot;. > This is not the first time Marjorie Taylor Greene made remarks viewed as anti-Asian, as she previously stated she would deport Chinese people who were loyal to the Chinese Communist Party. ***** [**Extended Summary**](http://np.reddit.com/r/autotldr/comments/rkmrrp/marjorie_taylor_greene_refers_to_yellow_people_in/) | [FAQ](http://np.reddit.com/r/autotldr/comments/31b9fm/faq_autotldr_bot/ \\\"Version 2.02, ~613684 tl;drs so far.\\\") | [Feedback](http://np.reddit.com/message/compose?to=%23autotldr \\\"PM's and comments are monitored, constructive feedback is welcome.\\\") | *Top* *keywords*: **people**^#1 **Yellow**^#2 **Asian**^#3 **how**^#4 **Greene**^#5\",\"Love it. Can this be a bot response please? I\\u2019d appreciate regularly coming across this poetry.\"],\"bot\":{\"__ndarray__\":\"cqWQW+wE0D8OhE0oe4jcP4AzqvpZiNw/nzpFSh5k5D84ovRFwKCzP2Jcoy4OM+k/fmLI9MXC4D9os1WRSU3jPw==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[8]},\"human\":{\"__ndarray__\":\"R6030on95z/5PdlrwrvhP0DmqgLTu+E/wop1a8M31z+5a0H354vtP3iOckXHM8s/AztvFnR63j8vmVTdbGXZPw==\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[8]}},\"selected\":{\"id\":\"11307\"},\"selection_policy\":{\"id\":\"11329\"}},\"id\":\"11306\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"11307\",\"type\":\"Selection\"},{\"attributes\":{\"end\":0.9899668894858702,\"reset_end\":0.9899668894858702,\"reset_start\":0.14587914535652707,\"start\":0.14587914535652707,\"tags\":[[[\"human\",\"human\",null]]]},\"id\":\"11273\",\"type\":\"Range1d\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#4b2362\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#4b2362\"},\"size\":{\"value\":5.477225575051661},\"x\":{\"field\":\"human\"},\"y\":{\"field\":\"bot\"}},\"id\":\"11310\",\"type\":\"Scatter\"},{\"attributes\":{\"axis\":{\"id\":\"11285\"},\"grid_line_color\":null,\"ticker\":null},\"id\":\"11288\",\"type\":\"Grid\"},{\"attributes\":{\"below\":[{\"id\":\"11285\"}],\"center\":[{\"id\":\"11288\"},{\"id\":\"11292\"}],\"height\":300,\"left\":[{\"id\":\"11289\"}],\"margin\":[5,5,5,5],\"min_border_bottom\":10,\"min_border_left\":10,\"min_border_right\":10,\"min_border_top\":10,\"renderers\":[{\"id\":\"11312\"}],\"sizing_mode\":\"fixed\",\"title\":{\"id\":\"11277\"},\"toolbar\":{\"id\":\"11299\"},\"width\":320,\"x_range\":{\"id\":\"11273\"},\"x_scale\":{\"id\":\"11281\"},\"y_range\":{\"id\":\"11274\"},\"y_scale\":{\"id\":\"11283\"}},\"id\":\"11276\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"client_comm_id\":\"20b310e9c8fd445b97541d7a5d605e1f\",\"comm_id\":\"868b91a5e83349f5b114fa42187a4e57\",\"plot_id\":\"11264\"},\"id\":\"11371\",\"type\":\"panel.models.comm_manager.CommManager\"},{\"attributes\":{\"children\":[{\"id\":\"11269\"}],\"margin\":[0,0,0,0],\"name\":\"Row16098\"},\"id\":\"11268\",\"type\":\"Row\"},{\"attributes\":{},\"id\":\"11316\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"children\":[{\"id\":\"11265\"}],\"margin\":[0,0,0,0],\"name\":\"Row16193\"},\"id\":\"11264\",\"type\":\"Row\"},{\"attributes\":{\"children\":[{\"id\":\"11266\"},{\"id\":\"11268\"},{\"id\":\"11272\"}],\"margin\":[0,0,0,0],\"name\":\"Column16192\"},\"id\":\"11265\",\"type\":\"Column\"},{\"attributes\":{},\"id\":\"11317\",\"type\":\"AllLabels\"},{\"attributes\":{\"active_multi\":null,\"tools\":[{\"id\":\"11275\"},{\"id\":\"11293\"},{\"id\":\"11294\"},{\"id\":\"11295\"},{\"id\":\"11296\"},{\"id\":\"11297\"}]},\"id\":\"11299\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"11319\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"11297\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"11329\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"value\":\"#4b2362\"},\"line_alpha\":{\"value\":0.2},\"line_color\":{\"value\":\"#4b2362\"},\"size\":{\"value\":5.477225575051661},\"x\":{\"field\":\"human\"},\"y\":{\"field\":\"bot\"}},\"id\":\"11311\",\"type\":\"Scatter\"},{\"attributes\":{\"margin\":[5,10,5,10],\"options\":[\"human\",\"bot\",\"Polarity\",\"Subjectivity\"],\"title\":\"y\",\"value\":\"bot\"},\"id\":\"11271\",\"type\":\"Select\"},{\"attributes\":{},\"id\":\"11295\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"axis_label\":\"bot\",\"formatter\":{\"id\":\"11319\"},\"major_label_policy\":{\"id\":\"11320\"},\"ticker\":{\"id\":\"11290\"}},\"id\":\"11289\",\"type\":\"LinearAxis\"},{\"attributes\":{\"fill_color\":{\"value\":\"#4b2362\"},\"line_color\":{\"value\":\"#4b2362\"},\"size\":{\"value\":5.477225575051661},\"x\":{\"field\":\"human\"},\"y\":{\"field\":\"bot\"}},\"id\":\"11309\",\"type\":\"Scatter\"},{\"attributes\":{\"axis\":{\"id\":\"11289\"},\"dimension\":1,\"grid_line_color\":null,\"ticker\":null},\"id\":\"11292\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"11283\",\"type\":\"LinearScale\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"syncable\":false,\"top_units\":\"screen\"},\"id\":\"11298\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"11294\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"11320\",\"type\":\"AllLabels\"},{\"attributes\":{\"margin\":[5,10,5,10],\"options\":[\"human\",\"bot\",\"Polarity\",\"Subjectivity\"],\"title\":\"x\",\"value\":\"human\"},\"id\":\"11270\",\"type\":\"Select\"}],\"root_ids\":[\"11264\",\"11371\"]},\"title\":\"Bokeh Application\",\"version\":\"2.3.3\"}};\n",
       "    var render_items = [{\"docid\":\"3621857a-be9f-4a85-a5af-c078f3f12b04\",\"root_ids\":[\"11264\"],\"roots\":{\"11264\":\"764e3c90-acf5-4616-8ba1-04ec1671f5aa\"}}];\n",
       "    root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "  if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined && root.Bokeh.Panel !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       "Row\n",
       "    [0] Column\n",
       "        [0] Row\n",
       "            [0] Markdown(str)\n",
       "        [1] Row\n",
       "            [0] Column\n",
       "                [0] Select(name='x', options=['human', 'bot', ...], value='human')\n",
       "                [1] Select(name='y', options=['human', 'bot', ...], value='bot')\n",
       "        [2] ParamFunction(function)"
      ]
     },
     "execution_count": 173,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "11264"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reactive_dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97043efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "#reactive_dashboard.save(\"bot_accusation.html\", embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16b21b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
